\begin{itemize}
    \item[] {\bf Bias} -- The measure of how closely our model matches the best possible estimator, with lower values representing a closer match.
    \item[] {\bf Variance} -- The measure of how much our model changes over i.i.d subsets of training data from the true probability distribution with lower values representing lower average differences.
    \item[] {\bf Bias-Variance Tradeoff} -- Together, bias and variance represent the two types of learning error. However, one cannot usually be reduced completely without increasing the other. This is because {\bf lowering bias tends to overfit the model which increases the variance}. Conversely, {\bf lowering variance reduces fit which increases bias}. Thus, an optimal model balances bias and variance accepting some degree of error.
\end{itemize}
